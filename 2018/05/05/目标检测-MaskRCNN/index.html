<!DOCTYPE html>
<html>
  <!DOCTYPE html>
<html lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  
  <title>目标检测-MaskRCNN - Zhk&#39;s Space</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
  
  <meta name="keywords" content="目标检测">
  
  
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.02">
  
  
    <link rel="alternate" href="/atom.xml " title="Zhk&#39;s Space" type="application/atom+xml">
  

  <link rel="stylesheet" href="/css/style.css">
</head></html>
  <body>
    <div class="container">
      <header class="header">
  <div class="blog-title">
    <a href="/" class="logo">Zhk&#39;s Space</a>
    <div class="subtitle">Learning and Fighting!!!</div>
  </div>
  <nav class="navbar">
    <ul class="menu">
      
        <li class="menu-item">
          <a href="/" class="menu-item-link">Home</a>
        </li>
      
        <li class="menu-item">
          <a href="/archives" class="menu-item-link">Archives</a>
        </li>
      
        <li class="menu-item">
          <a href="/about" class="menu-item-link">About</a>
        </li>
      
    </ul>
  </nav>
</header>
<article class="post">
  <div class="post-title">
    <h1 class="article-title">目标检测-MaskRCNN</h1>
  </div>
   <div class="post-meta">
    <span class="post-time">2018-05-05</span>
  </div>
  <div class="post-content">
    <p>这篇论文是2017年4月份的KaiMing大神的论文，又是一个里程碑的论文，综合了目标检测和<br>图像分割领域。现在COCO排行榜上基本都是以Mask RCNN为baseline改进的detector<br><a id="more"></a></p>
<h1 id="我的工作"><a href="#我的工作" class="headerlink" title="我的工作"></a>我的工作</h1><p>2017年12月份，我开始看这份工作，当初FB的<a href="https://github.com/facebookresearch/Detectron" target="_blank" rel="noopener">Detetron平台</a>还没开放出来，我选择了图森开放的mxnet版本的<a href="https://github.com/TuSimple/mx-maskrcnn" target="_blank" rel="noopener">mx-maskrcnn</a>，从此也开启了mxnet的炼丹之路。</p>
<h1 id="论文解读"><a href="#论文解读" class="headerlink" title="论文解读"></a>论文解读</h1><h2 id="文章的一些point"><a href="#文章的一些point" class="headerlink" title="文章的一些point"></a>文章的一些point</h2><p>1、Mask RCNN使用了<strong>RoiAlign</strong>代替了Faster rcnn的roipooling(对于特征的粗糙的空间<br>量化)，roiAlign能够解决像素点上的非对齐特质，尤其减弱了量化的粗糙性。<br>2、<strong>decouple</strong> mask和class的预测。我们独立地预测了一个二值的mask对于每个类，因&gt;此对于类之间没有了竞争，然后依靠roi的分类分支去预测类别。相比FCN，FCN使用了每个&gt;像素多个类别的分类，couple分割和分类，但是在我们这个实验上面，效果不是很好。<br>3、不像之前对于mask的预测是用fc层的，我们使用<strong>全卷积层</strong>的表示不仅<strong>减少了参数&gt;量而且更精确</strong>。<br>4、对于cityscape数据集，带标签的训练数据只有千张，所以对于小的数据集，用101-layer和50layer的差距不大<br>5、类别内重叠问题：我们的方法能够有效的提升<strong>重叠物体</strong>的分割精度<br>6、为了解决cityscape某些类物体训练样本少的问题，我们先用COCO做预训练，<br>7、我们专门使用了cls分支来去做class的预测，用来去选择<strong>mask分支</strong>的mask。<br>8、我们在mask分支使用<strong>FCN</strong>来预测m*m的mask，这样能够保持m*m的物体的空间结构而<br>且不用把他降维到缺少空间信息的向量表示。而且FCN相比于FC层需要更少的参数。</p>
<h2 id="实验对比"><a href="#实验对比" class="headerlink" title="实验对比"></a>实验对比</h2><p>1、FCN进行的语义分析，使用的是对每个像素softmax和多项交叉熵损失。而maskrcnn，使&gt;用的是对<strong>每个像素的softmax和二值损失</strong>。<br>2、类无关的mask：maskrcnn使用的一个单个的m*m的mask；而每个类一个m*m的mask的AP&gt;更低<br>3、使用FCN的全卷积代替MLP的全连接。<br>4、我们把Maskrcnn去掉mask 分支，就相当于可以表示成faster rcnn+roialign，他只比带<br>mask分支的maskrcnn低了0.9个AP点；所以这个0.9的提升在于多任务的训练<strong>(即检测和分&gt;割的合并训练)</strong></p>
<h2 id="论文的总结"><a href="#论文的总结" class="headerlink" title="论文的总结"></a>论文的总结</h2><p>　　Mask R-CNN是在faster R-CNN上的扩展，在其已有的用于bbx分支上添加了一个并行的&gt;用于预测目标掩码的分支。Mask R-CNN的训练很简单，只是在R-CNN的基础增加了少量的计&gt;算量，大约为5fps。另外，R-CNN掩码能够更好地适用于其他任务，例如估计同一图片中人&gt;物的姿态，本文在COCO挑战中的3种任务（包括实例分割、边界框目标探测、任务关键点检&gt;测）中都获得了最好的成绩。</p>
<h1 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h1><p>　　MaskRCNN是在Faster RCNN基础上做的改进。</p>
<p><strong>Faster RCNN</strong><br>　　faster RCNN由两个阶段组成，第一阶段为RPN，提出候选目标的bbox，第二阶段为fast RCNN的本质，使用RoiPool从每一个候选区域使用分类和bbox回归来提取特征。<br><strong>Mask RCNN</strong><br>　　Mask RCNN采用了相同的两部分，第一部分为RPN，第二部分为与预测class和box offset并行的对于每个Roi输出binary mask。<br>　　我们的方法跟随fast RCNN的灵感，应用bbox分类和回归并行的。(大大简化RCNN的多阶<br>段pipeline)<br>　　在训练的时候，我们定义了一个多任务的loss对于每个采样的Roi的损失函数Lclass+Lbox+Lmask。对每个RoI的mask分支，其输出维度为K*m*m。其中K表示对m*m的图像编码K个<br>二分类mask，每一个mask有K个类别。所以需要应用单像素的sigmoid进行二分类，并定义Lmask为平均二分类cross-entropy loss。对于类别为k的RoI，Lmask定义在第k个掩膜（其他&gt;掩膜输出对loss没贡献） 对Lmask的定义允许网络为每个类别生成mask且在类别之间没有竞<br>争。用专门的分类分支来预测类别标签（标签也用来选择输出mask），这样就解耦了类别与<br>mask预测。而FCN用的是单像素的softmax和multinomialcross-entropy loss，在这种情况&gt;下，mask和classes之间存在竞争，mask rcnn使用per-pixel sigmoid和binary loss就不会<br>。通过实验表时这是提高instance segmentation的关键点。</p>
<p><strong>Mask Representation:</strong><br>　　一个mask对目标的空间布局进行编码。因此不像class标签或者box offset必将通过全&gt;连接层进入一个短的output向量，提取空间结构的mask能够在像素级别即pixel-to-pixel下<br>完成(由对应的convolutions提供)，本质还是卷积代替全连接，维持空间信息。<br>　　对每个RoI，使用FCN预测m<em>m个mask，这就允许每个mask分支保持明确的m</em>m的目标空间<br>布局，而不用将其陷入向量描述（缺少空间维度）。不同于先前的模型使用fc layers进行mask预测，Mask RCNN的全连接层需要更少的参数，且精度更高<br>　　这种pixel-to-pixel的行为需要RoI特征，这些特征是小的特征图，为了一致的较好的&gt;保持明确的单像素空间对应关系，Mask RCNN提出了RoIAlign，这是对mask预测的关键。</p>
<p><strong>RoiAlign:</strong><br>　　RoIPool是对每个RoI提取小的特征图（比如7*7）的标准操作，RoiPool首先将一个floating number的RoI量化为discrete granularity（离散粒度）的特征图，然后被量化后的RoI被分成小的空间bin（本身已被量化），最后将每个bin聚合成特征值（通常使用maxpooling）。量化执行的方式为，比如[x/16]，其中16为特征图的stride，[]表示取整。同样的，<br>当划分bin（比如7*7）的时候，也要执行量化。 这些量化操作在RoI和提取的特征中引入&gt;了misaligments，这也许对分类没有影响，但对预测pixel-accurate的mask有较大的负面作<br>用。<br>　　移除RoIPool 的粗糙量化，从而调整特征的提取与输入。Mask rcnn提出的改变很简单&gt;：避免任何的RoI边界（boundaries）或者bin的量化（比如使用x/16而不是[x/16]）。我们<br>在每个RoI bin中的4个常规的采样位置使用双线性插值计算输入特征的准确值，并将结果融<br>合（使用max或average）。RoIAlign对算法有了很大的提高。</p>
<p><strong>网络结构</strong><br>　　Mask RCNN的结构分为3个部分，第一个是主干网络用来进行特征提取，第二个是头结构<br>用来做边界框识别（分类和回归），第三个就是mask预测用来对每一个ROI进行区分。<br>　　<strong>主干网络</strong>，使用了50层的<em>ResNet和FPN</em>(feature pyramid network)，这两种的结<br>合能够给Mask RCNN提供良好的精度和速度上的提升。<br>　　<strong>头结构</strong>，在网络的头部，我们近似使用faster rcnn之前的结构，添加一个全卷积mask预测分支。特别地，我们从ResNet和FPN来扩展Faster R-CNN box heads。 图3右部分是<br>该网络的头结构，其中14X14是空间分辨率spatial resolution，256是频道数，3X3卷积核&gt;进行卷积4次得到14X14X256，再2×2 且步长 stride为 2进行deconvs，并且在隐层使用ReLU，得到28X28X256再进行全连接得到输出，作为网络主干的输入。</p>
<h1 id="我的复现"><a href="#我的复现" class="headerlink" title="我的复现"></a>我的复现</h1><p>在4块TITAN X上跑了20多小时，把在cityscape上的数据结果跑出来了。<br>mAP=0.316<br><img src="img/maskrcnn.png"></p>

  </div>
  <div class="post-footer">
    
      <ul class="post-tag-list"><li class="post-tag-list-item"><a class="post-tag-list-link" href="/tags/目标检测/">目标检测</a></li></ul>
    

    <a href="#top" class="top">Back to Top</a>
  </div>
</article>
<footer>
  &copy; 2019
  <span class="author">
    Kai Zheng
  </span>
</footer>
    </div>
  </body>
</html>